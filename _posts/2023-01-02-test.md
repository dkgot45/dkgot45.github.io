# YoloV1 (1)

FPS 45로 실시간으로 영상처리 (fast yolo FPS 155)

다른 Real-time detector 보다 높은 mAP 

이미지 전체를 보므로 background error 낮음

## Unified Detection

![a](/assets/img/aaa.png)

image를 S by S로 나눔 ( 논문에선 S = 7)

각각의 Grid cell은 B개의 Bounding box와 이에 대한 confidence score 가진다. ( 논문에서 B = 2 ) 

total 7*7*2 = 98개의 Bounding box 있음

confidence score : $Pr( object)*IOU$

각각의 Grid cell은 C개의 Conditional Class Probability 가짐. ( 논문에서 C = 20 )

total 7*7*20 = 980개의 class probabilities 존재

Conditional Class Probability : $Pr(class_i|Object)$

각 Bounding box는 x,y좌표와 w,h, confidence 지님

x,y :  Bounding box의 중심점의 좌표, grid cell에 상대적인 값

w,h : 이미지 전체에 상대적인 width, height

Test time에서는 Class-Specitic Confidence Score 계산한다.  

![스크린샷 2022-02-18 오전 10.45.01.png](YoloV1%20(1)%20c712404253674edab53772e461b357c0/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-02-18_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_10.45.01.png)

## Network

![스크린샷 2022-02-18 오전 11.40.11.png](YoloV1%20(1)%20c712404253674edab53772e461b357c0/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-02-18_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_11.40.11.png)

입력 448*448*3 image

24개의 Conv layer 2개의 FC

출력 Tensor 7*7*30

7 by 7 개의 Grid

Grid Cell의 BBOX 2개 (B = 2 )의 x,y,w,h,confidence(총 10)

label 20개에 대한 Confidence Class Probability = > 30

각 BBOX의 confidence와 20개의 label에 관한 Confidence Class Probability가 곱해져 

Class-Specitic Confidence Score 계산됨

## Train

Pre-Train

Imagenet dataset 1000 class

20개의 convolutional layer와 average pooling layer, FC 사용

해상도 224,224에서 448,448로 높임

x,y를 특정 Grid cell 위치의 offset으로 설정

Leaky Relu 사용

![스크린샷 2022-02-18 오후 1.09.02.png](YoloV1%20(1)%20c712404253674edab53772e461b357c0/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-02-18_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_1.09.02.png)

sum-squared error(SSE) 사용했지만 목표하는 average precision 최대값에는 도달하지 못함

localization error와 classification error를 동등하게 두고 봤지만 이는 이상적이지 않을 수 있음

많은 Grid cell이 모든 object를 포함하지 않음

이를 해결하기 위해 object가 없는 box들에 대해 BBox predictions loss를 증가시키고 condfidence predictions loss를 감소 시킴 

![스크린샷 2022-02-18 오후 2.52.24.png](YoloV1%20(1)%20c712404253674edab53772e461b357c0/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-02-18_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_2.52.24.png)

Grid Cell의 BBox 중 Ground-turth box와의 IOU가 제일 높은 Bbox를 predictor로 선정

![스크린샷 2022-02-18 오후 1.26.33.png](YoloV1%20(1)%20c712404253674edab53772e461b357c0/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-02-18_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_1.26.33.png)

l_obj_ij : obj가 존재하는 Grid Cell i의 predictor BBox j

l_obj_i : object가 존재하는 Grid cell i

l_noobj_ij : object가 존재하지 않는 Grid cell i의 BBox j

SSE로 계산할 경우 큰 box는 작은 box와 같은 error여도 상대적으로 IOU에 영향을  덜 미침 

이런 영향을 고려해 w,h에 square root

## Inference

PASCAL VOC에서 image 당 98개의 BBox , 각 BBOX의  class probability 계산

여러 cell의 경계에 걸쳐 있는 object는 IOU가 높은 BBox만 남기고 제거 하여 사용

## **Limitations of YOLO**

spatial constraints ex) 작은물체의 그룹

data로 부터 BBox 예측하므로 특이한 비율로 구성된 객체 일반화 하기 어렵다.

loss function이 bbox에 크기에 상관없이 error를 동일하게 다룸 → 작은 bbox는 error에 따라 큰 영향